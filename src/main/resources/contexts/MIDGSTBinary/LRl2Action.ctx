value randomSeed="1";
value maxThreads="33";
value trainOnDev="false";
value errorExampleExtractor="FirstTokenSpan";
array validLabels=(
"NO_MILITARIZED_ACTION","THREAT_TO_USE_FORCE","THREAT_TO_BLOCKADE",
"THREAT_TO_OCCUPY_TERRITORY","THREAT_TO_DECLARE_WAR","THREAT_TO_USE_CBR_WEAPONS",
"THREAT_TO_JOIN_WAR","SHOW_OF_FORCE","ALERT","NUCLEAR_ALERT","MOBILIZATION",
"FORTIFY_BORDER","BORDER_VIOLATION","BLOCKADE",
"OCCUPATION_OF_TERRITORY","SEIZURE","ATTACK","CLASH","DECLARATION_OF_WAR","USE_OF_CBR_WEAPONS",
"BEGIN_INTERSTATE_WAR","JOIN_INTERSTATE_WAR");

evaluation accuracy=Accuracy();
evaluation accuracyBase=Accuracy(computeBaseline="true");
evaluation f.5=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="0.5");
evaluation f1=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="1");
evaluation prec=Precision(weighted="false", filterLabel="true");
evaluation recall=Recall(weighted="false", filterLabel="true");

ts_fn doc1=NGramDocument(n="1", noSentence="true");
ts_fn doc2=NGramDocument(n="2", noSentence="true");
ts_fn doc3=NGramDocument(n="3", noSentence="true");
ts_str_fn strBoW=String(cleanFn="CatBagOfWordsFeatureCleanFn");

feature fdoc1=TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="FirstTokenSpan", fn=(${strBoW} o ${doc1}));

model lr=Areg(l1="0", l2="0", convergenceEpsilon=".00001", maxTrainingExamples="520001", batchSize="100", evaluationIterations="200", maxEvaluationConstantIterations="500", weightedLabels="false", computeTestEvaluations="false")
{
	array validLabels=${validLabels};
};

gs g=GridSearch() {
	dimension l2=Dimension(name="l2", values=(.00000001,.0000001,.000001,.00001,.0001,.001,.01,.1,1,10), trainingDimension="true");
	dimension ct=Dimension(name="classificationThreshold", values=(.5,.6,.7,.8,.9), trainingDimension="false");

	model model=${lr};
	evaluation evaluation=${accuracy};
};

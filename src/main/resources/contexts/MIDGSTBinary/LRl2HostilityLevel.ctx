value randomSeed="1";
value maxThreads="33";
value trainOnDev="false";
value errorExampleExtractor="FirstTokenSpan";
array validLabels=("NO_MILITARIZED_ACTION","THREAT_TO_USE_FORCE","DISPLAY_OF_FORCE","USE_OF_FORCE","WAR");

evaluation accuracy=Accuracy();
evaluation accuracyBase=Accuracy(computeBaseline="true");
evaluation f.5=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="0.5");
evaluation f1=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="1");
evaluation prec=Precision(weighted="false", filterLabel="true");
evaluation recall=Recall(weighted="false", filterLabel="true");

ts_fn doc1=NGramDocument(n="1", noSentence="true");
ts_str_fn strBoW=String(cleanFn="CatBagOfWordsFeatureCleanFn");

feature fdoc1=TokenSpanFnDataVocab(scale="INDICATOR", minFeatureOccurrence="2", tokenExtractor="FirstTokenSpan", fn=(${strBoW} o ${doc1}));

model lr=Areg(l1="0", l2="0", convergenceEpsilon=".00001", maxTrainingExamples="520001", batchSize="100", evaluationIterations="200", maxEvaluationConstantIterations="500", weightedLabels="false", computeTestEvaluations="false")
{
	array validLabels=${validLabels};
};

gs g=GridSearch() {
	dimension l2=Dimension(name="l2", values=(.00000001,.0000001,.000001,.00001,.0001,.001,.01,.1,1,10), trainingDimension="true");
	dimension ct=Dimension(name="classificationThreshold", values=(.5,.6,.7,.8,.9), trainingDimension="false");
	
	model model=${lr};
	evaluation evaluation=${accuracy};
};

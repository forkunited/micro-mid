value randomSeed="1";
value maxThreads="33";
value trainOnDev="false";
value errorExampleExtractor="FirstTokenSpan";
array validLabels=("true", "false");
value positiveRate = ".01";
value biasedTrainingSample = "false";

evaluation accuracy=Accuracy();
evaluation accuracyBase=Accuracy(computeBaseline="true");
evaluation f3=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="3");
evaluation f2=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="2");
evaluation f1=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="1");
evaluation f.5=F(mode="MACRO_WEIGHTED", filterLabel="true", Beta="0.5");
evaluation prec=Precision(weighted="false", filterLabel="true");
evaluation recall=Recall(weighted="false", filterLabel="true");

ts_fn doc1=NGramDocument(n="1", noSentence="true");
ts_fn doc2=NGramDocument(n="2", noSentence="true");
ts_fn doc3=NGramDocument(n="3", noSentence="true");
ts_str_fn strBoW=String(cleanFn="CatBagOfWordsFeatureCleanFn");

feature fdoc1=TokenSpanFnDataVocab(scale="NORMALIZED_TFIDF", minFeatureOccurrence="2", tokenExtractor="FirstTokenSpan", fn=(${strBoW} o ${doc1}));

model lr=Areg(l1="0", l2="0", convergenceEpsilon=".00001", maxTrainingExamples="1000000", batchSize="100", evaluationIterations="400", maxEvaluationConstantIterations="500", weightedLabels="false", computeTestEvaluations="false")
{
	array validLabels=${validLabels};
};

gs g=GridSearch() {
	dimension l2=Dimension(name="l2", values=(.00000001,.0000001,.000001,.00001,.0001,.001,.01,.1,1,10), trainingDimension="true");
	dimension ct=Dimension(name="classificationThreshold", values=(.5,.6,.7,.8,.9), trainingDimension="false");

	model model=${lr};
	evaluation evaluation=${f3};
};
